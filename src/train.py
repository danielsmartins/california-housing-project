import joblib
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score
import warnings
import os

# Ignorar avisos de converg√™ncia (esperado pois controlamos o loop manualmente)
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

def load_processed_data():
    """Carrega os dados preparados anteriormente."""
    print("üîÑ Carregando dados processados...")
    processed_path = "data/processed"
    
    # Carregando tuplas (X, y)
    X_train, y_train = joblib.load(f"{processed_path}/train_data.pkl")
    X_val, y_val     = joblib.load(f"{processed_path}/val_data.pkl")
    
    # Carregando feature names apenas para log
    feature_names = joblib.load(f"{processed_path}/feature_names.pkl")
    
    print(f"‚úÖ Dados carregados. Features: {len(feature_names)}")
    return X_train, y_train, X_val, y_val

def train_model():
    X_train, y_train, X_val, y_val = load_processed_data()
    
    # config do MLP 
    # hidden_layer_sizes=(64, 32): Duas camadas ocultas.
    #   - 1¬™ com 64 neur√¥nios 
    #   - 2¬™ com 32 neur√¥nios 
    # activation='relu': Padr√£o moderno para Deep Learning.
    # solver='adam': Otimizador 
    # warm_start=True:  Permite treinar √©poca por √©poca sem resetar os pesos.
    model = MLPRegressor(
        hidden_layer_sizes=(64, 32),
        activation='relu',
        solver='adam',
        alpha=0.05,           # Regulariza√ß√£o para evitar overfitting
        learning_rate_init=0.001,
        max_iter=1,            # Treina 1 √©poca por vez no loop 
        warm_start=True,       # Mant√©m a mem√≥ria entre os loops
        random_state=42,
        verbose=False
    )
    
    # Listas para guardar o hist√≥rico (para o gr√°fico do relat√≥rio)
    train_loss_history = []
    val_loss_history = []
    
    epochs = 100  # N√∫mero total de √©pocas
    print(f"\n Iniciando treinamento por {epochs} √©pocas...")
    print(f"{'√âpoca':^10} | {'Train RMSE':^12} | {'Val RMSE':^12}")
    print("-" * 40)
    
    best_val_loss = float('inf')
    no_improvement_count = 0
    patience = 15  # Early Stopping: para se n√£o melhorar ap√≥s 15 √©pocas
    
    for epoch in range(1, epochs + 1):
        # Treina por 1 √©poca
        model.fit(X_train, y_train)
        
        # Avalia desempenho atual
        pred_train = model.predict(X_train)
        pred_val = model.predict(X_val)
        
        # Calculando RMSE (Root Mean Squared Error)
        train_rmse = np.sqrt(mean_squared_error(y_train, pred_train))
        val_rmse = np.sqrt(mean_squared_error(y_val, pred_val))
        
        # Salvando hist√≥rico
        train_loss_history.append(train_rmse)
        val_loss_history.append(val_rmse)
        
        # Log a cada 10 √©pocas
        if epoch % 10 == 0 or epoch == 1:
            print(f"{epoch:^10} | {train_rmse:^12.4f} | {val_rmse:^12.4f}")
            
        # L√≥gica de Early Stopping Manual 
        # Se o erro na valida√ß√£o for o menor at√© agora, salvamos esse modelo
        if val_rmse < best_val_loss:
            best_val_loss = val_rmse
            no_improvement_count = 0
            joblib.dump(model, "data/processed/best_model_mlp.pkl")
        else:
            no_improvement_count += 1
            
        if no_improvement_count >= patience:
            print(f"\nEarly Stopping ativado na √©poca {epoch}. Sem melhoria por {patience} √©pocas.")
            break
            
    print("\n Treinamento finalizado")
    
    # Plotando o gr√°fico de Loss
    plot_loss_curve(train_loss_history, val_loss_history)

def plot_loss_curve(train_loss, val_loss):
    """Gera o gr√°fico comparativo de erro Treino vs Valida√ß√£o."""
    plt.figure(figsize=(10, 6))
    plt.plot(train_loss, label='Treino (RMSE)')
    plt.plot(val_loss, label='Valida√ß√£o (RMSE)', linestyle='--')
    
    plt.title('Curva de Aprendizado (Loss Curve)')
    plt.xlabel('√âpocas')
    plt.ylabel('Erro (RMSE)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    save_path = "outputs/figures/loss_curve.png"
    plt.savefig(save_path, dpi=300)
    print(f" Gr√°fico de Loss salvo em: {save_path}")

if __name__ == "__main__":
    train_model()